{
  "tools": [
    {
      "name": "openai",
      "description": "Use OpenAI model to generate responses for various tasks including text generation, analysis, and creative writing",
      "provider": "openai",
      "modelClass": "ChatOpenAI",
      "defaultModel": "gpt-4-1106-preview",
      "modelOptions": [
        "gpt-4",
        "gpt-4-turbo",
        "gpt-3.5-turbo",
        "gpt-4-1106-preview"
      ]
    },
    {
      "name": "anthropic",
      "description": "Use Anthropic Claude model to generate responses, analysis, and creative content with advanced reasoning capabilities",
      "provider": "anthropic",
      "modelClass": "ChatAnthropic",
      "defaultModel": "claude-3-5-sonnet-20240620",
      "modelOptions": [
        "claude-3-5-sonnet-20240620",
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307"
      ]
    },
    {
      "name": "gemini",
      "description": "Use Google Gemini model for text generation, analysis, and creative tasks with multimodal capabilities",
      "provider": "google",
      "modelClass": "custom",
      "defaultModel": "gemini-1.5-pro",
      "modelOptions": [
        "gemini-1.5-pro",
        "gemini-1.5-flash",
        "gemini-pro",
        "gemini-pro-vision"
      ],
      "customParameters": {
        "temperature": {
          "type": "number",
          "description": "Sampling temperature for response generation",
          "minimum": 0,
          "maximum": 1
        }
      }
    },
    {
      "name": "cohere",
      "description": "Use Cohere models for text generation, classification, and semantic search tasks",
      "provider": "cohere",
      "modelClass": "custom",
      "defaultModel": "command-r-plus",
      "modelOptions": [
        "command-r-plus",
        "command-r",
        "command",
        "command-light"
      ]
    },
    {
      "name": "huggingface",
      "description": "Use Hugging Face models for various NLP tasks including text generation, translation, and analysis",
      "provider": "huggingface",
      "modelClass": "custom",
      "defaultModel": "meta-llama/Llama-2-7b-chat-hf",
      "modelOptions": [
        "meta-llama/Llama-2-7b-chat-hf",
        "meta-llama/Llama-2-13b-chat-hf",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "microsoft/DialoGPT-medium"
      ],
      "customParameters": {
        "temperature": {
          "type": "number",
          "description": "Sampling temperature for response generation"
        },
        "top_p": {
          "type": "number",
          "description": "Nucleus sampling parameter"
        }
      }
    }
  ]
}
